{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4110d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import requests\n",
    "from requests_html import HTMLSession\n",
    "import html5lib\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75289c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Scraping website to obtain a data set which can be used for analysis\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e359d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the connection\n",
    "\n",
    "# Indeed search for data analyst jobs, displaying 50 per page\n",
    "\n",
    "URL =\"https://www.indeed.com/jobs?as_and=data%20analyst&as_phr&as_any&as_not&as_ttl&as_cmp&jt=all&st&salary&radius=25&l&fromage=any&limit=50&sort&psf=advsrch&from=advancedsearch&vjk=44dce43f1d302551&advn=5680616533559579\"\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36 \"     \n",
    "          }  \n",
    "\n",
    "response = requests.get(URL,headers=headers)\n",
    "\n",
    "content = response.content\n",
    "\n",
    "# print(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ebbf003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using beautifulsoup to parse the HTMML\n",
    "\n",
    "\n",
    "soup1=BeautifulSoup(response.content, 'html.parser')\n",
    "soup = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11d641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "9\n",
      "2\n",
      "4\n",
      "30\n",
      "30\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "16\n",
      "4\n",
      "5\n",
      "2\n",
      "5\n",
      "18\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "16\n",
      "0\n",
      "22\n",
      "26\n",
      "2\n",
      "30\n",
      "9\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "30\n",
      "1\n",
      "19\n",
      "4\n",
      "3\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Cleaning date data to extract only numbers.\n",
    "\n",
    "DatePosted = soup.find_all(\"span\", class_=\"date\")\n",
    "for dates in DatePosted:\n",
    "    content = dates.text.replace('\\n','').strip()\n",
    "    content = content.replace('Employer','')\n",
    "    content = content.replace('Posted','')\n",
    "    content = content.replace('Active','')\n",
    "    content = content.replace('ago','')\n",
    "    content = content.replace('days','')\n",
    "    content = content.replace('day','')\n",
    "    content = content.replace('Just posted','0')     # Consider jobs posted today as 0 days ago\n",
    "    content = content.replace('To','0')\n",
    "    content = content.replace('30+','30')            # Jobs Posted 30+ days ago as 30 days ago\n",
    "    content = re.sub(\"^\\s+|\\s+$\", \"\", content, flags=re.UNICODE)\n",
    "    print(content)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a1d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "Company_Names=[] \n",
    "Dates_Posted = []\n",
    "Job_Titles = []\n",
    "Company_Locations=[]\n",
    "Job_Salaries = []\n",
    "\n",
    "\n",
    "# Creating lists and turning the list data into a datframe and cleaning up string and date data.\n",
    "\n",
    "\n",
    "    \n",
    "Titles = soup.find_all(\"h2\", class_=\"jobTitle\")\n",
    "for title in Titles:\n",
    "    data = title.text.replace('\\n','').strip()\n",
    "    data = data.replace('new','')\n",
    "    data = re.sub(r\"^\\s+\", \"\", data, flags=re.UNICODE)\n",
    "    data = re.sub('\\â€”','',str(data))\n",
    "    Job_Titles.append(data)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "CompanyNames = soup.find_all(\"span\",class_=\"companyName\")\n",
    "for name in CompanyNames:\n",
    "    content = name.text.strip().replace(\".\", \"\")\n",
    "    editedSource = re.sub('\\â€”','',str(content))\n",
    "    Company_Names.append(content)\n",
    "\n",
    "\n",
    "DatePosted = soup.find_all(\"span\", class_=\"date\")\n",
    "for dates in DatePosted:\n",
    "    content = dates.text.replace('\\n','').strip()\n",
    "    content = content.replace('Employer','')\n",
    "    content = content.replace('Posted','')\n",
    "    content = content.replace('Active','')\n",
    "    content = content.replace('ago','')\n",
    "    content = content.replace('days','')\n",
    "    content = content.replace('day','')\n",
    "    content = content.replace('Just posted','0')     # Consider jobs posted today as 0 days ago\n",
    "    content = content.replace('To','0')              # day removed, jobs posted today 'to' set as 0\n",
    "    content = content.replace('30+','30')            # Jobs Posted 30+ days ago as 30 days ago\n",
    "    content = re.sub(\"^\\s+|\\s+$\", \"\", content, flags=re.UNICODE)\n",
    "    Dates_Posted.append(content)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "CompanyLocation = soup.find_all(\"div\",class_=\"companyLocation\")\n",
    "for loca in CompanyLocation:\n",
    "    dataloc = loca.text.replace('\\n','').strip()\n",
    "    dataloc = dataloc.replace('(','')\n",
    "    dataloc = dataloc.replace(')','')\n",
    "    dataloc = dataloc.replace('+','')\n",
    "    dataloc = dataloc.replace('locations','')\n",
    "    dataloc = dataloc.replace('location','')\n",
    "    dataloc = dataloc.replace('  ','')\n",
    "    dataloc = re.sub('\\d', '', dataloc)\n",
    "    dataloc = re.sub(\"^\\s+|\\s+$\", \"\", dataloc, flags=re.UNICODE)\n",
    "    Company_Locations.append(dataloc)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#SalaryRange = soup.find_all(\"div\",class_=\"metadata salary-snippet-container\")\n",
    "#for sal in SalaryRange:\n",
    "#    Job_Salaries.append((sal.text.strip()))\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85880cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          Job Title  \\\n",
      "0                                                      Data Analyst   \n",
      "1                                           Operations Data Analyst   \n",
      "2                           Data Analyst + Apprentice (Entry-Level)   \n",
      "3                                                Data Entry Analyst   \n",
      "4                                                      Data Analyst   \n",
      "5                                        Public Health Data Analyst   \n",
      "6                                               Energy Data Analyst   \n",
      "7                      Entry Level Proposal Specialist/Data Analyst   \n",
      "8                                                   IT Data Analyst   \n",
      "9                                                      Data Analyst   \n",
      "10                                                     Data Analyst   \n",
      "11                                                 Business Analyst   \n",
      "12                                         Data Analyst Entry Level   \n",
      "13                                              Junior Data Analyst   \n",
      "14                                         Data Analyst Entry Level   \n",
      "15                                          Data Operations Analyst   \n",
      "16                                                     Data Analyst   \n",
      "17                                                     Data Analyst   \n",
      "18                                    Data Entry/Compliance Analyst   \n",
      "19                                         Entry Level Data Analyst   \n",
      "20                                                     Data Analyst   \n",
      "21                                       Entry Level - Data Analyst   \n",
      "22                                  Data Analyst Supporting the FBI   \n",
      "23                                                     Data Analyst   \n",
      "24                                          Data Analyst – Bootcamp   \n",
      "25                                          Data Processing Analyst   \n",
      "26                                  Entry level Data Analyst/Python   \n",
      "27                                        Data Analyst- Entry Level   \n",
      "28                                                   Energy Analyst   \n",
      "29                                        Junior level Data Analyst   \n",
      "30                                                     Data Analyst   \n",
      "31  Data Analyst, Business Analysis and Reporting – VIRTUAL/REMO...   \n",
      "32                                              Junior Data Analyst   \n",
      "33                                          Healthcare Data Analyst   \n",
      "34  Data Analyst - Store Ops & Analytics (Full Time Remote OR Hy...   \n",
      "35                             Research Technician and Data Analyst   \n",
      "36                                         Data Analyst-entry level   \n",
      "37                                     Data Analyst- Full Time Role   \n",
      "38                                                     Data Analyst   \n",
      "39                        Junior Data Analyst/ Entry Level position   \n",
      "40                                                     Data Analyst   \n",
      "41                                                     Data Analyst   \n",
      "42                                                     Data Analyst   \n",
      "43                             Entry - Junior Data Analyst - Onsite   \n",
      "44                                                     Data Analyst   \n",
      "45                                                     Data Analyst   \n",
      "46                                                 Jr. Data Analyst   \n",
      "47                                                     Data Analyst   \n",
      "48                                                     Data Analyst   \n",
      "49                                              Junior Data Analyst   \n",
      "\n",
      "                                 Company Name  \\\n",
      "0                               Cannon Sports   \n",
      "1                               Good Day Farm   \n",
      "2                          New Apprenticeship   \n",
      "3                         Mid Valley Disposal   \n",
      "4                                 CarPartscom   \n",
      "5     Central Jersey Family Health Consortium   \n",
      "6                         Energy Intelligence   \n",
      "7                      Sunsolar Solutions Inc   \n",
      "8                          Silverton Mortgage   \n",
      "9                                    FlowWest   \n",
      "10                      Cenergy International   \n",
      "11                                     1Starr   \n",
      "12                            PCS GLOBAL TECH   \n",
      "13                                  Avalanche   \n",
      "14                            PCS GLOBAL TECH   \n",
      "15                                   Vendelux   \n",
      "16                              Slim Chickens   \n",
      "17                                  Microsoft   \n",
      "18                               Latitude Inc   \n",
      "19                             Talentheed Inc   \n",
      "20                                 PRIMMA LLC   \n",
      "21                             General Motors   \n",
      "22                                FSA Federal   \n",
      "23                            Agama Solutions   \n",
      "24                            PCS Global Tech   \n",
      "25                            EnergyWatch Inc   \n",
      "26                                    Emonics   \n",
      "27                              AC Accounting   \n",
      "28                                      Tesla   \n",
      "29                                    TRESUME   \n",
      "30                           Disney Streaming   \n",
      "31                                     Publix   \n",
      "32                     Cobbs Creek Healthcare   \n",
      "33                  University of Connecticut   \n",
      "34                                     TARGET   \n",
      "35                California State University   \n",
      "36                                    TRESUME   \n",
      "37  Visionary Innovative Technology Solutions   \n",
      "38                           Novuskin Med Spa   \n",
      "39                            PCS GLOBAL TECH   \n",
      "40                                 Inrika Inc   \n",
      "41                             CDC Foundation   \n",
      "42               UNIVERSITY OF SOUTH CAROLINA   \n",
      "43                                   Tier2Tek   \n",
      "44                      VSOFT CORPORATION INC   \n",
      "45                      WEBTOON Entertainment   \n",
      "46                                 Colsh Tech   \n",
      "47            Bronco Billy's Casino and Hotel   \n",
      "48                                Robert Half   \n",
      "49                              CCR Analytics   \n",
      "\n",
      "                       Company Location Days Posted Ago  \n",
      "0                           Pacoima, CA               0  \n",
      "1               Hot Springs Village, AR               3  \n",
      "2   Raleigh, NC  Northwest Raleigh area               4  \n",
      "3                            Kerman, CA               2  \n",
      "4                     Grand Prairie, TX               3  \n",
      "5                   North Brunswick, NJ               9  \n",
      "6        New York, NY  Murray Hill area               2  \n",
      "7                            Peoria, AZ               4  \n",
      "8                                Remote              30  \n",
      "9              Remote in Sacramento, CA              30  \n",
      "10                           Spring, TX               2  \n",
      "11                               Remote               5  \n",
      "12                      Los Angeles, CA               2  \n",
      "13                               Remote               5  \n",
      "14                      Los Angeles, CA               3  \n",
      "15                               Remote               2  \n",
      "16                     Fayetteville, AR               2  \n",
      "17           Redmond, WA  Overlake area              16  \n",
      "18                         Manassas, VA               4  \n",
      "19                         San Jose, CA               5  \n",
      "20                           Roslyn, NY               2  \n",
      "21              Remote in United States               5  \n",
      "22                        Linthicum, MD              18  \n",
      "23                        United States               2  \n",
      "24                           Dallas, TX               4  \n",
      "25                               Remote               4  \n",
      "26                               Remote               2  \n",
      "27                            Tampa, FL               4  \n",
      "28                               Remote              16  \n",
      "29                          Ashburn, VA               0  \n",
      "30                         New York, NY              22  \n",
      "31               Remote in Lakeland, FL              26  \n",
      "32                   Newtown Square, PA               2  \n",
      "33                       Farmington, CT              30  \n",
      "34            Remote in Minneapolis, MN               9  \n",
      "35              Fresno, CA  Hoover area               2  \n",
      "36                          Herndon, VA               3  \n",
      "37                         New York, NY               2  \n",
      "38                        Las Vegas, NV               1  \n",
      "39                            Poway, CA               2  \n",
      "40      Township of South Brunswick, NJ              30  \n",
      "41       Hybrid remote in Pago Pago, AS               1  \n",
      "42                         Columbia, SC              19  \n",
      "43                     Delray Beach, FL               4  \n",
      "44                           McLean, VA               3  \n",
      "45                      Los Angeles, CA               8  \n",
      "46                               Remote               2  \n",
      "47                    Cripple Creek, CO               2  \n",
      "48    Houston, TX  Galleria-Uptown area               2  \n",
      "49                               Remote               3  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame( \n",
    "{  'Job Title' : Job_Titles,\n",
    "    'Company Name': Company_Names,\n",
    "    'Company Location': Company_Locations,\n",
    "    'Days Posted Ago': Dates_Posted,\n",
    " #   'Salary Range': Job_Salaries}\n",
    "}, columns=[\"Job Title\", \"Company Name\", \"Company Location\", \"Days Posted Ago\"]\n",
    ")\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('IndeedScraping.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77842d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a9882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb5009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a25fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89238cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
