{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4110d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from requests_html import HTMLSession\n",
    "import html5lib\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e492f39-da88-4b0a-a823-5eb19cda90dd",
   "metadata": {},
   "source": [
    "\n",
    "Scraping indeed job boards to obtain a data set which can be used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e359d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the connection\n",
    "\n",
    "# Indeed search for data analyst jobs, displaying 50 per page\n",
    "\n",
    "URL =\"https://www.indeed.com/jobs?as_and=data%20analyst&as_phr&as_any&as_not&as_ttl&as_cmp&jt=all&st&salary&radius=25&l&fromage=any&limit=50&sort&psf=advsrch&from=advancedsearch&vjk=44dce43f1d302551&advn=5680616533559579\"\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36 \"     \n",
    "          }  \n",
    "\n",
    "response = requests.get(URL,headers=headers)\n",
    "\n",
    "content = response.content\n",
    "\n",
    "# print(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ebbf003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using beautifulsoup to parse the HTMML\n",
    "\n",
    "\n",
    "soup1=BeautifulSoup(response.content, 'html.parser')\n",
    "soup = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffe57fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Hiring ongoing\n",
      "0\n",
      "3\n",
      "11\n",
      "2\n",
      "30\n",
      "2\n",
      "0\n",
      "30\n",
      "30\n",
      "9\n",
      "14\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "11\n",
      "3\n",
      "13\n",
      "30\n",
      "1\n",
      "2\n",
      "30\n",
      "19\n",
      "2\n",
      "3\n",
      "0\n",
      "30\n",
      "30\n",
      "7\n",
      "2\n",
      "30\n",
      "4\n",
      "2\n",
      "3\n",
      "30\n",
      "2\n",
      "3\n",
      "17\n",
      "30\n",
      "30\n",
      "30\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "10\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Cleaning date data to extract only numbers.\n",
    "\n",
    "DatePosted = soup.find_all(\"span\", class_=\"date\")\n",
    "for dates in DatePosted:\n",
    "    content = dates.text.replace('\\n','').strip()\n",
    "    content = content.replace('Employer','')\n",
    "    content = content.replace('Posted','')\n",
    "    content = content.replace('Active','')\n",
    "    content = content.replace('ago','')\n",
    "    content = content.replace('days','')\n",
    "    content = content.replace('day','')\n",
    "    content = content.replace('Just posted','0')     # Consider jobs posted today as 0 days ago\n",
    "    content = content.replace('To','0')\n",
    "    content = content.replace('30+','30')            # Jobs Posted 30+ days ago as 30 days ago\n",
    "    content = re.sub(\"^\\s+|\\s+$\", \"\", content, flags=re.UNICODE)\n",
    "    print(content)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a1d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "Company_Names=[] \n",
    "Dates_Posted = []\n",
    "Job_Titles = []\n",
    "Company_Locations=[]\n",
    "Job_Salaries = []\n",
    "\n",
    "\n",
    "# Creating lists and turning the list data into a datframe and cleaning up string and date data.\n",
    "\n",
    "\n",
    "\n",
    "CompanyNames = soup.find_all(\"span\",class_=\"companyName\")\n",
    "for name in CompanyNames:\n",
    "    content = name.text.strip().replace(\".\", \"\")\n",
    "    editedSource = re.sub('\\â€”','',str(content))\n",
    "    Company_Names.append(content)\n",
    "\n",
    "\n",
    "DatePosted = soup.find_all(\"span\", class_=\"date\")\n",
    "for dates in DatePosted:\n",
    "    content = dates.text.replace('\\n','').strip()\n",
    "    content = content.replace('Employer','')\n",
    "    content = content.replace('Posted','')\n",
    "    content = content.replace('Active','')\n",
    "    content = content.replace('ago','')\n",
    "    content = content.replace('days','')\n",
    "    content = content.replace('day','')\n",
    "    content = content.replace('Just posted','0')     # Consider jobs posted today as 0 days ago\n",
    "    content = content.replace('To','0')              # day removed, jobs posted today 'to' set as 0\n",
    "    content = content.replace('30+','30')            # Jobs Posted 30+ days ago as 30 days ago\n",
    "    content = re.sub(\"^\\s+|\\s+$\", \"\", content, flags=re.UNICODE)\n",
    "    Dates_Posted.append(content)\n",
    "    \n",
    "    \n",
    "    \n",
    "Titles = soup.find_all(\"h2\", class_=\"jobTitle\")\n",
    "for title in Titles:\n",
    "    data = title.text.replace('\\n','').strip()\n",
    "    data = data.replace('new','')\n",
    "    data = re.sub(r\"^\\s+\", \"\", data, flags=re.UNICODE)\n",
    "    data = re.sub('\\â€”','',str(data))\n",
    "    Job_Titles.append(data)\n",
    "\n",
    "\n",
    "\n",
    "CompanyLocation = soup.find_all(\"div\",class_=\"companyLocation\")\n",
    "for loca in CompanyLocation:\n",
    "    dataloc = loca.text.replace('\\n','').strip()\n",
    "    dataloc = dataloc.replace('(','')\n",
    "    dataloc = dataloc.replace(')','')\n",
    "    dataloc = dataloc.replace('+','')\n",
    "    dataloc = dataloc.replace('locations','')\n",
    "    dataloc = dataloc.replace('location','')\n",
    "    dataloc = dataloc.replace('  ','')\n",
    "    dataloc = re.sub('\\d', '', dataloc)\n",
    "    dataloc = re.sub(\"^\\s+|\\s+$\", \"\", dataloc, flags=re.UNICODE)\n",
    "    Company_Locations.append(dataloc)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#SalaryRange = soup.find_all(\"div\",class_=\"metadata salary-snippet-container\")\n",
    "#for sal in SalaryRange:\n",
    "#    Job_Salaries.append((sal.text.strip()))\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191af975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          Job Title  \\\n",
      "0                           Data and Research Analyst - Entry Level   \n",
      "1                                               Junior Data Analyst   \n",
      "2                                            Associate Data Analyst   \n",
      "3                                                      Data Analyst   \n",
      "4                                                      Data Analyst   \n",
      "5                                  International Trade Data Analyst   \n",
      "6                               Web Data Analyst (North of Chicago)   \n",
      "7                                                Laboratory Analyst   \n",
      "8   Data Analyst/Architect -100% remote - MUST have Active Secre...   \n",
      "9                           Data Analyst / Sr. Data Analyst, Remote   \n",
      "10                                                     Data Analyst   \n",
      "11                                         Collections Data Analyst   \n",
      "12                                             Data Systems Analyst   \n",
      "13                         Saybrus Partners- Data Reporting Analyst   \n",
      "14                                              Health Data Analyst   \n",
      "15  Program Data Analyst - The Connor Group's Kids & Community P...   \n",
      "16                                                     Data Analyst   \n",
      "17                                            Business Data Analyst   \n",
      "18                                      Data and Assessment Analyst   \n",
      "19                                         Data Analyst (Analyst 4)   \n",
      "20                                                     Data Analyst   \n",
      "21                                            Business Data Analyst   \n",
      "22                                                     Data Analyst   \n",
      "23                                                  HR Data Analyst   \n",
      "24                   Solutions Analyst (Data Analytics & Reporting)   \n",
      "25                                                 Business Analyst   \n",
      "26                                      Data Analyst and Researcher   \n",
      "27                                        Data Analyst - Operations   \n",
      "28                                     Human Resources Data Analyst   \n",
      "29                                     Data Analyst - Oklahoma City   \n",
      "30                                         Data Analyst Entry Level   \n",
      "31                        Junior Data Analyst/ Entry Level position   \n",
      "32                                                 Business Analyst   \n",
      "33                                          Healthcare Data Analyst   \n",
      "34                                         Data Analyst Entry Level   \n",
      "35                                          Data Operations Analyst   \n",
      "36                                           Portfolio Data Analyst   \n",
      "37                                          Research Analyst (Data)   \n",
      "38                                                     Data Analyst   \n",
      "39                          Data Analyst + Apprentice (Entry-Level)   \n",
      "40                   PT Football Data Collection Analyst (Contract)   \n",
      "41                                             Fraud Data Analyst -   \n",
      "42                                                     Data Analyst   \n",
      "43                                                     Data Analyst   \n",
      "44      Analytics & Data Science, Professional, Informatics Analyst   \n",
      "45                                         Data Analyst-entry level   \n",
      "46                                               Operations Analyst   \n",
      "47                 Medical Record/Data Analyst Virtual Hiring Event   \n",
      "48                           Data Analyst, Toyota Big Data Platform   \n",
      "49  Data Analyst (Epidemiologist / Statistician / Health Science...   \n",
      "\n",
      "                                          Company Name  \\\n",
      "0                     Cloudburst Consulting Group, Inc   \n",
      "1                                       Talentheed Inc   \n",
      "2                       SYNQ3 Restaurant Solutions LLC   \n",
      "3                                   Sun Life Financial   \n",
      "4                       Central Coast Community Energy   \n",
      "5                     UNO International Trade Strategy   \n",
      "6                                                Uline   \n",
      "7                                         Almatis, Inc   \n",
      "8                                            SecurePro   \n",
      "9                             Liberty Mutual Insurance   \n",
      "10                                                Hulu   \n",
      "11   Clerk of the Circuit Court and County Comptroller   \n",
      "12                                          PMHCC, INC   \n",
      "13                                    Saybrus Partners   \n",
      "14                                          One Health   \n",
      "15                                    The Connor Group   \n",
      "16                                           Equisolar   \n",
      "17                                     First Mile Care   \n",
      "18                             Fremont School District   \n",
      "19                          Oregon Judicial Department   \n",
      "20                   Business Performance Systems, LLC   \n",
      "21                             Eloquest Healthcare Inc   \n",
      "22                                      CDC Foundation   \n",
      "23                                           Odoo, Inc   \n",
      "24                                           SYSTEMTEC   \n",
      "25                                              1Starr   \n",
      "26               Integra Realty Resources - Fort Worth   \n",
      "27                              Dreamfields Brands Inc   \n",
      "28                                              Kroger   \n",
      "29                          CDC Foundation ( Contract)   \n",
      "30                                     PCS GLOBAL TECH   \n",
      "31                                     PCS GLOBAL TECH   \n",
      "32                             Ana-Data Consulting Inc   \n",
      "33                           University of Connecticut   \n",
      "34                                     PCS GLOBAL TECH   \n",
      "35                                            Vendelux   \n",
      "36  Virginia Innovation Partnership Corporation (VIPC)   \n",
      "37                                                 MIT   \n",
      "38                                Elitetech Recruiters   \n",
      "39                                  New Apprenticeship   \n",
      "40                                                 PFF   \n",
      "41                                               Apple   \n",
      "42                            Fastline Marketing Group   \n",
      "43                                        Excel Impact   \n",
      "44                                     MVP Health Care   \n",
      "45                                             TRESUME   \n",
      "46                         Marathon Energy Corporation   \n",
      "47                    Telecare Corporation- Santa Cruz   \n",
      "48                                              Toyota   \n",
      "49             SMITREC, Department of Veterans Affairs   \n",
      "\n",
      "                           Company Location Days Posted Ago  \n",
      "0                              Landover, MD              14  \n",
      "1                                    Remote  Hiring ongoing  \n",
      "2                                    Remote               0  \n",
      "3                       Wellesley Hills, MA               3  \n",
      "4                              Monterey, CA              11  \n",
      "5        Bethesda, MD  Bethesda Center area               2  \n",
      "6                               Chicago, IL              30  \n",
      "7                                Benton, AR               2  \n",
      "8                                    Remote               0  \n",
      "9                                    Remote              30  \n",
      "10                         Santa Monica, CA              30  \n",
      "11              Sarasota, FL  Downtown area               9  \n",
      "12                         Philadelphia, PA              14  \n",
      "13                                   Remote               2  \n",
      "14                               Powell, WY               2  \n",
      "15                           Miamisburg, OH               3  \n",
      "16                               Encino, CA               0  \n",
      "17                          Northampton, MA               2  \n",
      "18                            Mundelein, IL              11  \n",
      "19                   Remote in Portland, OR               3  \n",
      "20     Temporarily Remote in Washington, DC              13  \n",
      "21                             Ferndale, MI              30  \n",
      "22                                   Remote               1  \n",
      "23  Temporarily Remote in San Francisco, CA               2  \n",
      "24            Hybrid remote in Columbia, SC              30  \n",
      "25                                   Remote              19  \n",
      "26                           Fort Worth, TX               2  \n",
      "27                   Desert Hot Springs, CA               3  \n",
      "28                                   Remote               0  \n",
      "29                                   Remote              30  \n",
      "30                             New York, NY              30  \n",
      "31                      California City, CA               7  \n",
      "32               New York, NY  Midtown area               2  \n",
      "33                           Farmington, CT              30  \n",
      "34                               Austin, TX               4  \n",
      "35                                   Remote               2  \n",
      "36                                 Virginia               3  \n",
      "37                  Cambridge, MA  MIT area              30  \n",
      "38                  Remote in United States               2  \n",
      "39                           Richardson, TX               3  \n",
      "40                 Remote in Cincinnati, OH              17  \n",
      "41                               Austin, TX              30  \n",
      "42                                   Remote              30  \n",
      "43                                     Ohio              30  \n",
      "44                             New York, NY               8  \n",
      "45                              Herndon, VA               3  \n",
      "46                   Remote in Syracuse, NY               3  \n",
      "47                               Gilroy, CA               3  \n",
      "48                                Plano, TX              10  \n",
      "49                            Ann Arbor, MI               7  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame( \n",
    "{  'Job Title' : Job_Titles,\n",
    "    'Company Name': Company_Names,\n",
    "    'Company Location': Company_Locations,\n",
    "    'Days Posted Ago': Dates_Posted,\n",
    " #   'Salary Range': Job_Salaries}\n",
    "}, columns=[\"Job Title\", \"Company Name\", \"Company Location\", \"Days Posted Ago\"]\n",
    ")\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('IndeedScraping.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03a9882",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Function to automate this process - \n",
    "\n",
    "def scrap_indeed():\n",
    "    import datetime\n",
    "    import csv\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    import requests\n",
    "    from requests_html import HTMLSession\n",
    "    import html5lib\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    \n",
    "    URL =\"https://www.indeed.com/jobs?as_and=data%20analyst&as_phr&as_any&as_not&as_ttl&as_cmp&jt=all&st&salary&radius=25&l&fromage=any&limit=50&sort&psf=advsrch&from=advancedsearch&vjk=44dce43f1d302551&advn=5680616533559579\"\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36 \"     \n",
    "          }  \n",
    "\n",
    "    response = requests.get(URL,headers=headers)\n",
    "    content = response.content\n",
    "    soup1=BeautifulSoup(response.content, 'html.parser')\n",
    "    soup = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "\n",
    "    Company_Names=[] \n",
    "    Dates_Posted = []\n",
    "    Job_Titles = []\n",
    "    Company_Locations=[]\n",
    "    Job_Salaries = []\n",
    "\n",
    "\n",
    "    CompanyNames = soup.find_all(\"span\",class_=\"companyName\")\n",
    "    for name in CompanyNames:\n",
    "        content = name.text.strip().replace(\".\", \"\")\n",
    "        editedSource = re.sub('\\â€”','',str(content))\n",
    "        Company_Names.append(content)\n",
    "\n",
    "\n",
    "    DatePosted = soup.find_all(\"span\", class_=\"date\")\n",
    "    for dates in DatePosted:\n",
    "        content = dates.text.replace('\\n','').strip()\n",
    "        content = content.replace('Employer','')\n",
    "        content = content.replace('Posted','')\n",
    "        content = content.replace('Active','')\n",
    "        content = content.replace('ago','')\n",
    "        content = content.replace('days','')\n",
    "        content = content.replace('day','')\n",
    "        content = content.replace('Just posted','0')     # Consider jobs posted today as 0 days ago\n",
    "        content = content.replace('To','0')              # day removed, jobs posted today 'to' set as 0\n",
    "        content = content.replace('30+','30')            # Jobs Posted 30+ days ago as 30 days ago\n",
    "        content = re.sub(\"^\\s+|\\s+$\", \"\", content, flags=re.UNICODE)\n",
    "        Dates_Posted.append(content)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Titles = soup.find_all(\"h2\", class_=\"jobTitle\")\n",
    "    for title in Titles:\n",
    "        data = title.text.replace('\\n','').strip()\n",
    "        data = data.replace('new','')\n",
    "        data = re.sub(r\"^\\s+\", \"\", data, flags=re.UNICODE)\n",
    "        data = re.sub('\\â€”','',str(data))\n",
    "        Job_Titles.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    CompanyLocation = soup.find_all(\"div\",class_=\"companyLocation\")\n",
    "    for loca in CompanyLocation:\n",
    "        dataloc = loca.text.replace('\\n','').strip()\n",
    "        dataloc = dataloc.replace('(','')\n",
    "        dataloc = dataloc.replace(')','')\n",
    "        dataloc = dataloc.replace('+','')\n",
    "        dataloc = dataloc.replace('locations','')\n",
    "        dataloc = dataloc.replace('location','')\n",
    "        dataloc = dataloc.replace('  ','')\n",
    "        dataloc = re.sub('\\d', '', dataloc)\n",
    "        dataloc = re.sub(\"^\\s+|\\s+$\", \"\", dataloc, flags=re.UNICODE)\n",
    "        Company_Locations.append(dataloc)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame( \n",
    "    {  'Job Title' : Job_Titles,\n",
    "        'Company Name': Company_Names,\n",
    "        'Company Location': Company_Locations,\n",
    "        'Days Posted Ago': Dates_Posted,}\n",
    "    , columns=[\"Job Title\", \"Company Name\", \"Company Location\", \"Days Posted Ago\"]\n",
    "    )\n",
    "\n",
    "    \n",
    "    with open('IndeedScraping.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "        writer=csv.writer(f)\n",
    "        writer.writerow(data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while(True):\n",
    "    scrap_indeed()\n",
    "    time.sleep(1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d6481-dd10-4997-9a2a-e078e4c97ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
